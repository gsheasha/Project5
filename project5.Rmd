Project
Here I used PCA and random forest plot

#Loading required libraries
```{r,echo=FALSE,message=FALSE}
library(caret)
library(dplyr)
library(randomForest)
```
# Loading the data
```{r, cache=T}
if (!file.exists("pml-training.csv")) {
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",method = "auto",destfile = "pml-training.csv")
}
if (!file.exists("pml-testing.csv")) {
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",method = "auto",destfile = "pml-testing.csv")
}
training<-read.csv("pml-training.csv",stringsAsFactors=F,na.strings=c("","#DIV/0!","NA"))
testing<-read.csv("pml-testing.csv",stringsAsFactors=F,na.strings=c("","#DIV/0!","NA"))
```

# Preprocessing of the data file

## Cleaning of the data file
I cleaned the data file by removing all irrelevant and useless predictors
### Rememoving irrelevant variables
first I removed all the variables that were unrelated to the prediction. i.e., the first seven variables
```{r}
training<-training[,8:160]
testing<-testing[,8:160]
```


### Removing useless varibles
Then, I removed all variables with zero variance as they will of no value in prediction
```{r}

nsv<-nearZeroVar(training)
nsv
training<-(training[-nsv])
testing<-(testing[-nsv])
dim(training);dim(testing)
```
## Pre-processing of the data file
Before pre-processing of the data, I have to remove the outcome varialbe-after saving it in an object named outcome-and convert the variables into numeric variables
```{r}
#save the training$class into outcome 
outcome<-training$classe
#Remove the outcome variable
training$classe<-NULL
#Convert all variable into numeric
new<-sapply(training,as.numeric)
#convert the dataframe into notcentered
notcentered<-as.data.frame(new)
```
I imputed missing values using knn method
```{r}

preProc3<-preProcess(notcentered,method="knnImpute")
dim(notcentered)
imputed<-predict(preProc3,notcentered)
dim(notcentered);dim(imputed)
```
# Fitting of a randomforest model
Before I applied the model, I splited traing into train and test
```{r}
imputed$classe<-outcome
set.seed(123)
inTrain <- createDataPartition(y=imputed$classe,p=0.75, list=FALSE)
train <- imputed[inTrain,]
test <- imputed[-inTrain,]
rbind("original dataset" = dim(imputed),
      "training set" = dim(train),
      "testing set"=dim(test))
table(train$classe)
table(test$classe)
```



#Exploratory data analysis


I trained the random forest model.
```{r}
#Train a randomForest model
dim(train);dim(test);names(train)
y<-train$classe
y<-as.factor(y)
x<-train[,1:117]
modFit <- randomForest(x,y,
                importance=T,ntree=200, nodesize=25)
```
I determine the important variables by arrangind them according to the number of trees that use them
The following plot shows the predictors arranged according to their importance in prediction
```{r}
##PLot used variables
vu<-varUsed(modFit,count=T)
vusorted = sort(vu, decreasing = F, index.return = TRUE)
vusorteddes = sort(vu, decreasing = T, index.return = TRUE)
dotchart(vusorted$x, names(modFit$forest$xlevels[vusorted$ix]))
```
I save the indices of the important pedictors in a vector named imp. I used to select the important predictors in the new model
```{r}
imp<-vusorteddes$ix[1:30]
imp
x2<-train[,imp]
dim(x2)
modFit2 <- randomForest(x2,y,
                       importance=T,ntree=200, nodesize=25)
```
To evaluate the perfromance of the two models, the redudnant model- the model with all the predictor- and the concise model- the model containing the most important 30 predictors only. The performance of the concise model is a little higher than that of the redundant model althought it uses only 30 predictors.Thus, we will use the concise model
#Predict the performance of the redundant model
predictions=predict(modFit,test)
#Predict the performance of the consice model
predictions2=predict(modFit2,test)
rbind("Accuracy of the redundant model"=confusionMatrix(test$classe,predictions)$overall[1], "Accuracy of the concise model"=confusionMatrix(test$classe,predictions2)$overall[1])


# Predict the test set
First, we have to prepare the testing set to be used for prediction. We have to convert it into numeric variables before imputing the missing values

```{r}
testing$classe<-NULL
newTest<-sapply(testing,as.numeric)
notcenteredTest<-as.data.frame(newTest)
imputedTest<-predict(preProc3,notcenteredTest[,1:117])
```
I used the concise model to predict the outcome variable in the test set

```{r}
predictTest2<-predict(modFit2,imputedTest)
predictTest2
```

I used the following function to save the differet predicted values into 20 text file for submission
```{r}

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(predictTest2)
```
